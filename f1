{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc #garbage collector\n",
    "import sys\n",
    "import os\n",
    "from pandas.api.types import CategoricalDtype\n",
    "#from xgboost import XGBRegressor as xgb\n",
    "import xgboost as xgb\n",
    "from itertools import product\n",
    "from statistics import stdev \n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_pdf\n",
    "from datetime import date\n",
    "import pickle\n",
    "import pyodbc\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from datetime import date\n",
    "from xgboost import XGBRegressor\n",
    "from dateutil.relativedelta import *\n",
    "from pandas import ExcelWriter\n",
    "\n",
    "\n",
    "from sklearn2pmml import sklearn2pmml\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn2pmml import PMMLPipeline\n",
    "from sklearn2pmml import Pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn2pmml.decoration import CategoricalDomain, ContinuousDomain\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, StandardScaler\n",
    "from sklearn2pmml.preprocessing.xgboost import make_xgboost_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn2pmml.preprocessing import PMMLLabelEncoder\n",
    "from sklearn2pmml import make_pmml_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "##### Helper Functions #####\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_na_report(df):\n",
    "    \"\"\"\n",
    "    create a report of variables whose values are NA across all table, and eliminate them\n",
    "    \"\"\"\n",
    "    print(\"\\nDataset has {} entries and {} features\".format(*df.shape))\n",
    "    na_report = df.isna().sum()                          #create a list of columns and sum of null values\n",
    "    na_report = pd.DataFrame(na_report, index=None)     #convert list to a dataframe\n",
    "    na_report.reset_index(inplace=True)                  #reset index to range(0 : len(df)-1)\n",
    "    na_report.columns = [\"variable\", \"na_count\"]        #set column names\n",
    "    na_report[\"perc\"] = na_report[\"na_count\"]/df.shape[0]           #add a new column which is percentage of null vales by column name\n",
    "    gc.collect()                                                #garbage collecter for memory efficiency\n",
    "    return na_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dtype_report(df):\n",
    "    \"\"\"\n",
    "    define the following reports:\n",
    "    num_cols: indicating which variables are numeric\n",
    "    char_cols: indicating which variables are of type character\n",
    "    \"\"\"\n",
    "    df.replace({True: 1, False: 0}, inplace=True)\n",
    "    df_cols = df.columns\n",
    "    num_cols = list(df._get_numeric_data().columns)\n",
    "    char_cols = list(set(df_cols) - set(num_cols))\n",
    "    gc.collect()\n",
    "    return num_cols, char_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_missing(df, na_report, max_threshold):\n",
    "    ''' \n",
    "    # define maximum threshold of missing percentage\n",
    "    # eliminate columns that do not fit the threshold\n",
    "    '''\n",
    "    cols_before = df.columns.tolist()\n",
    "    cols_ = df.columns[df.columns.isin(list(na_report[na_report['perc'] < max_threshold]['variable']) or df.columns.isin(list(key_var)))]\n",
    "    df = df[cols_]\n",
    "    print(len(cols_before)-len(cols_),\"columns eliminated due to missing values\")\n",
    "    del cols_, cols_before\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_single_unique(df):\n",
    "    ''' \n",
    "    # eliminate columns having a single unique value \n",
    "    '''\n",
    "    cols_before = df.columns.tolist()\n",
    "    unique_report = df.nunique()                          \n",
    "    unique_report = pd.DataFrame(unique_report, index=None)    \n",
    "    unique_report.reset_index(inplace=True)\n",
    "    unique_report.columns = [\"variable\", \"number_unique\"]        #set column names\n",
    "    unique_report = unique_report[~unique_report['variable'].isin(key_var)]  #discard key variables  \n",
    "    u_cols = df.columns[~df.columns.isin(list(unique_report[unique_report['number_unique'] == 1]['variable']))]\n",
    "    df = df[u_cols]\n",
    "    print(len(cols_before)-len(u_cols),\"columns eliminated due to single unique values, namely:\",list(set(cols_before) - set(u_cols)))\n",
    "    del unique_report, u_cols, cols_before\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoding_matrix(df):\n",
    "    \"\"\"\n",
    "    create a matrix (or dataframe) with 2 columns:\n",
    "    variable: categorical columns of dataframe\n",
    "    levels: levels of unique values in categorical columns (including missing values)\n",
    "    \"\"\"\n",
    "    missing_string = \"MISSING\"\n",
    "    df_temp = df.copy()\n",
    "    cols = list(set(list(df_temp.select_dtypes(include=['category', 'object']).columns)) - set(key_vars))\n",
    "    assert len(cols) == len(set(cols)) , \"please ensure that you are using unique column names.\"\n",
    "    enc_df = pd.DataFrame(columns = [\"variable\", \"levels\"])\n",
    "    for i in cols:\n",
    "        if (pd.api.types.is_categorical_dtype(df_temp[i])):\n",
    "            df_temp[i] = df_temp[i].cat.add_categories([missing_string])       \n",
    "        df_temp[i] = df_temp[i].fillna(value=missing_string)\n",
    "        colLevels = list(df_temp[i].unique())\n",
    "        if missing_string not in colLevels:\n",
    "           colLevels.append(missing_string)\n",
    "        enc_df = enc_df.append({'variable' : i , 'levels' : colLevels} , ignore_index=True)\n",
    "    del df_temp, cols\n",
    "    gc.collect()\n",
    "    return enc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_from_matrix(df, enc_df):\n",
    "    \"\"\"\n",
    "    transforms categorical columns into numeric values based on encoded matrix\n",
    "    enc_df: result of create_encoding_matrix() function composed of 2 columns:\n",
    "        variable: categorical columns of dataframe\n",
    "        levels: levels of unique values in categorical columns (including missing values)\n",
    "    \"\"\"\n",
    "    missing_string = \"MISSING\"\n",
    "    df_temp = df.copy()\n",
    "    matrix_cols = list(enc_df['variable'].values)\n",
    "    for i in matrix_cols:\n",
    "        if (pd.api.types.is_categorical_dtype(df_temp[i])):\n",
    "            df_temp[i] = df_temp[i].cat.add_categories([missing_string])\n",
    "        df_temp[i] = df_temp[i].fillna(value=missing_string)\n",
    "        df_temp[i] = df_temp[i].astype('category')\n",
    "        temp_levels = list(enc_df[enc_df['variable']==i]['levels'])[0]\n",
    "        df_temp[i] = pd.Categorical(df_temp[i], categories=temp_levels).codes +1\n",
    "        del temp_levels\n",
    "    del matrix_cols\n",
    "    gc.collect()\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Modelleme asamalari iÃ§in gerekli fonksiyonlar##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_mae_and_mape(df, sample='train', pred_name='predicted'):\n",
    "    temp = df.copy()\n",
    "    mae_ = mean_absolute_error(temp.loc[temp['sample'] == sample]['actual'], temp.loc[temp['sample'] == sample][pred_name])   \n",
    "    mape_ = np.mean(np.abs((temp.loc[temp['sample'] == sample]['actual']-temp.loc[temp['sample'] == sample][pred_name])/temp.loc[temp['sample'] == sample]['actual'])) \n",
    "    del temp\n",
    "    gc.collect()\n",
    "    return mae_,mape_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(dictionary):\n",
    "   \"\"\"Create a dataframe from every combination of given values.\"\"\"\n",
    "   return pd.DataFrame([row for row in product(*dictionary.values())],\n",
    "                       columns=dictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_split_index(df, splitting_perc, seed, min_date):\n",
    "    # allocate Development, and OOT validation data\n",
    "    oot_index = df.loc[df['APP_DATE'] >= min_date].index.values\n",
    "    dev_index = df.loc[df['APP_DATE'] < min_date].index.values  \n",
    "    \n",
    "    y_all = df['TARGET'].iloc[dev_index]\n",
    "    \n",
    "    train_index, test_index, y_train, y_test = train_test_split(dev_index, y_all, test_size=splitting_perc, random_state=seed)   #, stratify=y_all Ã§ikarildi\n",
    "    print(\"\\nShape of dataframes; train: {}, test: {}, oot: {}\".format(train_index.shape,test_index.shape,oot_index.shape))\n",
    "    print(\"\\nPercentage of dataframes; train: {:.2%}, test: {:.2%}, oot: {:.2%}\".format(len(train_index)/len(df),len(test_index)/len(df),len(oot_index)/len(df)))\n",
    "    return train_index, test_index, oot_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_by_index(df, key_var, train_index, test_index, oot_index):\n",
    "    # first get TARGET arrays\n",
    "    y_train, y_test, y_oot = df['TARGET'].iloc[train_index], df['TARGET'].iloc[test_index], df['TARGET'].iloc[oot_index]\n",
    "    \n",
    "    # get key values apart including TARGET\n",
    "    cols_ = df.columns[df.columns.isin(list(key_var))] #including TARGET\n",
    "    df_key_var = df[cols_]  #save key values\n",
    "    df_n = df.drop(cols_, axis=1)\n",
    "    \n",
    "    # set dataframes\n",
    "    X_train, X_test, X_oot = df_n.iloc[train_index], df_n.iloc[test_index], df_n.iloc[oot_index]\n",
    "    train_keys, test_keys, oot_keys = df_key_var.iloc[train_index], df_key_var.iloc[test_index], df_key_var.iloc[oot_index]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    doot = xgb.DMatrix(X_oot, label=y_oot)\n",
    "    del df_n\n",
    "    gc.collect()\n",
    "    return dtrain, dtest, doot, y_train, y_test, y_oot, train_keys, test_keys, oot_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_measurement_results(df, title):\n",
    "    df_sum = df.copy()\n",
    "    \n",
    "    divide_by_score = np.arange(0, 100001, 1000)\n",
    "    divide_by_cnt = 10\n",
    "   \n",
    "    df_sum['score_grp'] = pd.cut(df_sum['predicted'], divide_by_score).astype('category')\n",
    "    temp_score = df_sum.groupby(\"score_grp\")[\"actual\", \"predicted\", \"count\",\"score_grp\"].agg(\"sum\").reset_index() #, observed=True\n",
    "    temp_score=temp_score[temp_score['count']!=0]\n",
    "    temp_score.index = np.arange(1, len(temp_score) + 1)\n",
    "    \n",
    "    df_sum['row'] = np.arange(1, df_sum.shape[0]+1)\n",
    "    df_sum['row_grp'] = pd.cut(df_sum['row'], divide_by_cnt).astype('category')\n",
    "    temp_row = df_sum.groupby(\"row_grp\")[\"actual\", \"predicted\", \"count\",\"score_grp\"].agg(\"sum\").reset_index() #, observed=True \n",
    "    temp_row=temp_row[temp_row['count']!=0]\n",
    "    temp_row.index = np.arange(1, len(temp_row) + 1)\n",
    "    \n",
    "    temp_score['act_avg_pd'] = temp_score[\"actual\"]/temp_score[\"count\"]\n",
    "    temp_score['pred_avg_pd'] = temp_score[\"predicted\"]/temp_score[\"count\"]\n",
    "    temp_score['dist'] = temp_score[\"count\"]/df_sum.shape[0]\n",
    "    \n",
    "    temp_row['act_avg_pd'] = temp_row[\"actual\"]/temp_row[\"count\"]\n",
    "    temp_row['pred_avg_pd'] = temp_row[\"predicted\"]/temp_row[\"count\"]\n",
    "    temp_row['dist'] = temp_row[\"count\"]/df_sum.shape[0]\n",
    "    \n",
    "    fig_score = plt.figure()\n",
    "    plt.plot(temp_score[\"act_avg_pd\"], '-r')  # red\n",
    "    plt.plot(temp_score[\"pred_avg_pd\"], '--b')  # blue\n",
    "    #plt.plot(temp_row[\"count\"],marker=\".\",linestyle=\"\",color=\"tan\")\n",
    "    plt.legend(['Actual', 'Predicted'], loc='upper right', shadow=True)\n",
    "    plt.title(title+\" - Average PD by Score\")\n",
    "    plt.xlabel(\"Score bins\")\n",
    "    plt.ylabel(\"pd\")\n",
    "    plt.close()\n",
    "    \n",
    "    fig_row = plt.figure()\n",
    "    plt.plot(temp_row[\"act_avg_pd\"], '-r')  # red\n",
    "    plt.plot(temp_row[\"pred_avg_pd\"], '--b')  # blue\n",
    "    plt.legend(['Actual', 'Predicted'], loc='upper right', shadow=True)\n",
    "    plt.title(title+\" - Average PD by Population Bins\")\n",
    "    plt.xlabel(\"Population bins\")\n",
    "    plt.ylabel(\"pd\")\n",
    "    plt.close()\n",
    "    del df_sum\n",
    "    gc.collect()\n",
    "    return temp_score, temp_row, fig_score, fig_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridsearch kapalÄ±ysa buradaki parametrelerle aÅaÄÄ±daki akÄ±Å Ã§alÄ±ÅÄ±r:\n",
    "def set_params(seed): \n",
    "    params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'eta' : 0.01,\n",
    "    'max_depth': 15, #15\n",
    "    'min_child_weight': 250, #75\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'gamma' : 40,\n",
    "    'reg_alpha' :0.1,\n",
    "    #'scale_pos_weight':  5,\n",
    "    # Other parameters\n",
    "    'objective': \"reg:squarederror\",\n",
    "    'eval_metric' : \"mae\",\n",
    "    'booster' : \"gbtree\",\n",
    "    'seed' : seed\n",
    "    }\n",
    "    return params \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "### Part 6 - Run GRID search ###\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_grid_search(df, key_var, grid_params, splitting_perc, min_date, seed, random_search, diff_threshold, grid_size):\n",
    "        \n",
    "    train_index, test_index, oot_index = set_split_index(df, splitting_perc, seed, min_date)\n",
    "    dtrain, dtest, doot, y_train, y_test, y_oot, train_keys, test_keys, oot_keys = split_df_by_index(df, key_var, train_index, test_index, oot_index)\n",
    "    \n",
    "    evallist = [(dtrain, 'train'),(dtest, 'eval')]\n",
    "    \n",
    "    grid_params = expand_grid(grid_params)\n",
    "    \n",
    "    if random_search:\n",
    "        grid_params = grid_params.sample(n=grid_size, replace = False, random_state=seed)\n",
    "        \n",
    "    xgb_gs = pd.DataFrame() #create xgboost grid search dataframe\n",
    "    \n",
    "    iter_count = 0\n",
    "    for i in range(grid_params.shape[0]):\n",
    "        params = {\n",
    "            'eta' : grid_params['eta'].iloc[i],\n",
    "            'max_depth': grid_params['max_depth'].iloc[i],\n",
    "            'min_child_weight': grid_params['min_child_weight'].iloc[i],\n",
    "            'subsample': grid_params['subsample'].iloc[i],\n",
    "            'colsample_bytree': grid_params['colsample_bytree'].iloc[i],\n",
    "            'gamma' : grid_params['gamma'].iloc[i],  # [10, 20, 30, 40]\n",
    "            'reg_alpha' : grid_params['reg_alpha'].iloc[i],\n",
    "            # Other parameters\n",
    "            'objective': grid_params['objective'].iloc[i],\n",
    "            'eval_metric' : grid_params['eval_metric'].iloc[i],\n",
    "            'booster' : grid_params['booster'].iloc[i],\n",
    "            'seed' : seed           \n",
    "            }\n",
    "        iter_count = iter_count+1\n",
    "        print('\\niteration:', iter_count)\n",
    "        bst = xgb.train(params=params, dtrain=dtrain, num_boost_round=500, evals=evallist, early_stopping_rounds=20, verbose_eval=50 )\n",
    "        \n",
    "        pred_train = bst.predict(dtrain, ntree_limit=bst.best_ntree_limit)\n",
    "        pred_test = bst.predict(dtest, ntree_limit=bst.best_ntree_limit) \n",
    "        pred_oot = bst.predict(doot, ntree_limit=bst.best_ntree_limit)\n",
    "        \n",
    "        train_df = pd.DataFrame({'sample': 'train', \n",
    "                                  'actual': y_train, \n",
    "                                  'predicted' : pred_train\n",
    "                                #  'FM_CUSTOMER_ID':, \n",
    "                                #  'REPORT_DATE': , \n",
    "                                  })\n",
    "        test_df = pd.DataFrame({'sample': 'test', \n",
    "                                  'actual': y_test, \n",
    "                                  'predicted' : pred_test\n",
    "                                #  'FM_CUSTOMER_ID':, \n",
    "                                #  'REPORT_DATE': , \n",
    "                                  })\n",
    "        oot_df = pd.DataFrame({'sample': 'oot', \n",
    "                                  'actual': y_oot, \n",
    "                                  'predicted' : pred_oot\n",
    "                                #  'FM_CUSTOMER_ID':, \n",
    "                                #  'REPORT_DATE': , \n",
    "                                  })\n",
    "        predictions = train_df.append([test_df, oot_df])\n",
    "        ##predictions[['actual', 'predicted']] = predictions[['actual', 'predicted']].apply(lambda x: round(100*x, 2))\n",
    "\n",
    "        mae_train, mape_train = cal_mae_and_mape(predictions, sample='train',pred_name='predicted')\n",
    "        mae_test, mape_test = cal_mae_and_mape(predictions, sample='test',pred_name='predicted')\n",
    "        mae_oot, mape_oot = cal_mae_and_mape(predictions, sample='oot', pred_name='predicted')\n",
    "        \n",
    "        perf_sum = predictions.groupby(\"sample\").agg(\"mean\").reset_index()\n",
    "        #perf_sum[['actual', 'predicted']] = perf_sum[['actual', 'predicted']].apply(lambda x: round(100*x, 2))\n",
    "        \n",
    "        perf_sum['mae'] = 0\n",
    "        perf_sum.loc[perf_sum['sample'] == 'train', 'mae'] = mae_train\n",
    "        perf_sum.loc[perf_sum['sample'] == 'test', 'mae'] = mae_test\n",
    "        perf_sum.loc[perf_sum['sample'] == 'oot', 'mae'] = mae_oot\n",
    "        \n",
    "        perf_sum['mape'] = 0\n",
    "        perf_sum.loc[perf_sum['sample'] == 'train', 'mape'] = mape_train\n",
    "        perf_sum.loc[perf_sum['sample'] == 'test', 'mape'] = mape_test\n",
    "        perf_sum.loc[perf_sum['sample'] == 'oot', 'mape'] = mape_oot\n",
    "\n",
    "        \n",
    "        perf_sum['eta'] = grid_params['eta'].iloc[i]\n",
    "        perf_sum['max_depth'] = grid_params['max_depth'].iloc[i]\n",
    "        perf_sum['min_child_weight'] = grid_params['min_child_weight'].iloc[i]\n",
    "        perf_sum['subsample'] = grid_params['subsample'].iloc[i]\n",
    "        perf_sum['colsample_bytree'] = grid_params['colsample_bytree'].iloc[i]\n",
    "        perf_sum['gamma'] = grid_params['gamma'].iloc[i]\n",
    "        perf_sum['reg_alpha'] = grid_params['reg_alpha'].iloc[i]\n",
    "        perf_sum['objective'] = grid_params['objective'].iloc[i]\n",
    "        perf_sum['eval_metric'] = grid_params['eval_metric'].iloc[i]\n",
    "        perf_sum['booster'] = grid_params['booster'].iloc[i]\n",
    "        perf_sum['grid_iter'] = iter_count\n",
    "        \n",
    "        xgb_gs = xgb_gs.append(perf_sum, ignore_index=True)\n",
    "        \n",
    "        del mape_train, mape_test, mape_oot, mae_train, mae_test, mae_oot, bst, predictions, train_df, test_df, oot_df, pred_train, pred_test, pred_oot\n",
    "        gc.collect()\n",
    "        \n",
    "    print(\"\\n----selecting best grid iteration----\")\n",
    "    #select best grid results\n",
    "    xgb_gs_train = xgb_gs.loc[xgb_gs['sample'] == \"train\"]\n",
    "    xgb_gs_train = xgb_gs_train.sort_values('mae', ascending=False)\n",
    "    \n",
    "    best_gs_iter = np.nan\n",
    "    xgb_gs_train['trainMae'] = np.nan\n",
    "    xgb_gs_train['testMae'] = np.nan\n",
    "    xgb_gs_train['ootMae'] = np.nan\n",
    "    xgb_gs_train['testDiff'] = np.nan\n",
    "    xgb_gs_train['ootDiff'] = np.nan\n",
    "    xgb_gs_train['avgDiff'] = np.nan\n",
    "    \n",
    "    for i in xgb_gs_train.index:\n",
    "        iter_ = xgb_gs_train.loc[i, 'grid_iter']\n",
    "            \n",
    "        train_mae = xgb_gs.loc[(xgb_gs['grid_iter'] == iter_) & (xgb_gs['sample']=='train'), 'mae'].iloc[0]\n",
    "        test_mae = xgb_gs.loc[(xgb_gs['grid_iter'] == iter_) & (xgb_gs['sample']=='test'), 'mae'].iloc[0]\n",
    "        oot_mae = xgb_gs.loc[(xgb_gs['grid_iter'] == iter_) & (xgb_gs['sample']=='oot'), 'mae'].iloc[0]    \n",
    "        \n",
    "        xgb_gs_train.loc[i, 'trainMae'] = train_mae\n",
    "        xgb_gs_train.loc[i, 'testMae'] = test_mae\n",
    "        xgb_gs_train.loc[i, 'ootMae'] = oot_mae\n",
    "        xgb_gs_train.loc[i, 'testDiff'] = abs(train_mae - test_mae)\n",
    "        xgb_gs_train.loc[i, 'ootDiff'] = abs(train_mae - oot_mae)\n",
    "        xgb_gs_train.loc[i, 'avgDiff'] = (abs(train_mae - test_mae) + abs(train_mae - oot_mae))/2\n",
    "\n",
    "    del i, iter_, train_mae, test_mae, oot_mae\n",
    "    gc.collect()\n",
    "\n",
    "    xgb_gs_train_base = xgb_gs_train.copy()\n",
    "    xgb_gs_train = xgb_gs_train.loc[xgb_gs_train['mae'] > 0].copy()\n",
    "    minAvgDiff = xgb_gs_train['avgDiff'].min()\n",
    "\n",
    "    if minAvgDiff <= diff_threshold:\n",
    "        xgb_gs_train_f = xgb_gs_train.loc[xgb_gs_train['avgDiff'] <= diff_threshold].copy()\n",
    "        min_train_mae = xgb_gs_train_f['trainMae'].min()\n",
    "        \n",
    "        xgb_gs_train_f['StdDev'] = np.nan\n",
    "        xgb_gs_train_f['trainMaePrevious'] = min_train_mae\n",
    "        xgb_gs_train_f['trainMaePreviousDiff'] = np.nan\n",
    "        xgb_gs_train_f['finalEvaluationScore'] = np.nan\n",
    "        \n",
    "        for i in xgb_gs_train_f.index: \n",
    "            train_mae = xgb_gs_train_f.loc[i, 'trainMae']\n",
    "            test_mae = xgb_gs_train_f.loc[i, 'testMae']\n",
    "            oot_mae = xgb_gs_train_f.loc[i, 'ootMae']\n",
    "            xgb_gs_train_f.loc[i, 'StdDev'] = stdev([train_mae,test_mae,oot_mae])\n",
    "            xgb_gs_train_f.loc[i, 'trainMaePreviousDiff'] = train_mae - min_train_mae\n",
    "            xgb_gs_train_f.loc[i, 'finalEvaluationScore'] = ((0.50 * xgb_gs_train_f.loc[i, 'trainMaePreviousDiff']) + (0.20 * xgb_gs_train_f.loc[i, 'avgDiff']) + (0.3 * xgb_gs_train_f.loc[i, 'StdDev']))\n",
    "            \n",
    "            \n",
    "        xgb_gs_train = pd.merge(xgb_gs_train,xgb_gs_train_f[['grid_iter','StdDev', 'trainMaePrevious', 'trainMaePreviousDiff','finalEvaluationScore']],on='grid_iter', how='left')\n",
    "        min_final_eva_score = copy.copy(xgb_gs_train_f['finalEvaluationScore'].min())\n",
    "        best_gs_iter = xgb_gs_train_f.loc[xgb_gs_train_f['finalEvaluationScore'] <= min_final_eva_score, 'grid_iter'].iloc[0]\n",
    "        xgb_gs_train = pd.merge(xgb_gs_train_base,xgb_gs_train[['grid_iter','StdDev', 'trainMaePrevious', 'trainMaePreviousDiff','finalEvaluationScore']],on='grid_iter', how='left')\n",
    "        del i, train_mae, test_mae, oot_mae\n",
    "        gc.collect()\n",
    "    else:\n",
    "        min_diff = xgb_gs_train['avgDiff'].min()\n",
    "        min_diff_mae = xgb_gs_train.loc[xgb_gs_train['avgDiff'] <= minAvgDiff, 'trainMae'].iloc[0]\n",
    "        for i in xgb_gs_train.index:\n",
    "            #iter_ = j['grid_iter']\n",
    "            diff_increase = xgb_gs_train.loc[i, 'avgDiff'] - min_diff\n",
    "            mae_decrease = xgb_gs_train.loc[i, 'trainMae'] - min_diff_mae\n",
    "            xgb_gs_train.loc[i, 'finalEvaluationScore'] = 5*diff_increase - mae_decrease\n",
    "        \n",
    "        min_final_eva_score = xgb_gs_train['finalEvaluationScore'].min()\n",
    "        best_gs_iter = xgb_gs_train.loc[xgb_gs_train['finalEvaluationScore'] <= min_final_eva_score, 'grid_iter'].iloc[0]\n",
    "        xgb_gs_train = xgb_gs_train.reset_index(drop=True)\n",
    "        xgb_gs_train = pd.merge(xgb_gs_train_base,xgb_gs_train[['grid_iter','finalEvaluationScore']],on='grid_iter', how='left')\n",
    "        del i, diff_increase, mae_decrease, min_diff, min_diff_mae\n",
    "        gc.collect()\n",
    "    print(\"best grid iteration:\", best_gs_iter)\n",
    "    \n",
    "    params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'eta' : xgb_gs_train.loc[xgb_gs_train['grid_iter'] == best_gs_iter,'eta'].iloc[0],\n",
    "    'max_depth': xgb_gs_train.loc[xgb_gs_train['grid_iter'] == best_gs_iter,'max_depth'].iloc[0],\n",
    "    'min_child_weight': xgb_gs_train.loc[xgb_gs_train['grid_iter'] == best_gs_iter,'min_child_weight'].iloc[0],\n",
    "    'subsample': xgb_gs_train.loc[xgb_gs_train['grid_iter'] == best_gs_iter,'subsample'].iloc[0],\n",
    "    'colsample_bytree': xgb_gs_train.loc[xgb_gs_train['grid_iter'] == best_gs_iter,'colsample_bytree'].iloc[0],\n",
    "    'gamma' : xgb_gs_train.loc[xgb_gs_train['grid_iter'] == best_gs_iter,'gamma'].iloc[0],\n",
    "    'reg_alpha' : xgb_gs_train.loc[xgb_gs_train['grid_iter'] == best_gs_iter,'reg_alpha'].iloc[0],\n",
    "    # Other parameters\n",
    "    'objective': xgb_gs_train.loc[xgb_gs_train['grid_iter'] == best_gs_iter,'objective'].iloc[0],\n",
    "    'eval_metric' : xgb_gs_train.loc[xgb_gs_train['grid_iter'] == best_gs_iter,'eval_metric'].iloc[0],\n",
    "    'booster' : xgb_gs_train.loc[xgb_gs_train['grid_iter'] == best_gs_iter,'booster'].iloc[0],\n",
    "    'seed' : seed\n",
    "    }\n",
    "    xgb_gs_train[['actual', 'predicted']] = xgb_gs_train[['actual', 'predicted']].apply(lambda x: round(x, 2))\n",
    "\n",
    "    return xgb_gs_train, best_gs_iter, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "### Part 7 - Run final model with the best grid parameters ###\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_final_model(df, key_var, params, splitting_perc, seed, num_boost_round, early_stopping_rounds, verbose_eval):\n",
    "    print(\"\\n----final model----\")\n",
    "    train_index, test_index, oot_index = set_split_index(df, splitting_perc, seed, min_date)\n",
    "    dtrain, dtest, doot, y_train, y_test, y_oot, train_keys, test_keys, oot_keys = split_df_by_index(df, key_var, train_index, test_index, oot_index)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    evallist = [(dtrain, 'train'),(dtest, 'eval')]\n",
    "    \n",
    "    bst = xgb.train(params=params, dtrain=dtrain, num_boost_round=num_boost_round, evals=evallist, early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose_eval )\n",
    "    \n",
    "    pred_train = bst.predict(dtrain, ntree_limit=bst.best_ntree_limit)\n",
    "    pred_test = bst.predict(dtest, ntree_limit=bst.best_ntree_limit) \n",
    "    pred_oot = bst.predict(doot, ntree_limit=bst.best_ntree_limit)\n",
    "    \n",
    "    train_df = pd.DataFrame({'sample': 'train', \n",
    "                              'actual': y_train, \n",
    "                              'predicted' : pred_train,\n",
    "                              'RT_CUSTOMER_ID': train_keys[\"RT_CUSTOMER_ID\"], \n",
    "                              'APP_DATE': train_keys[\"APP_DATE\"],\n",
    "                              'APP_ID': train_keys[\"APP_ID\"]\n",
    "                              })\n",
    "    \n",
    "    test_df = pd.DataFrame({'sample': 'test', \n",
    "                             'actual': y_test, \n",
    "                             'predicted' : pred_test,\n",
    "                             'RT_CUSTOMER_ID': test_keys[\"RT_CUSTOMER_ID\"], \n",
    "                             'APP_DATE': test_keys[\"APP_DATE\"],\n",
    "                             'APP_ID': test_keys[\"APP_ID\"]\n",
    "                              })\n",
    "    oot_df = pd.DataFrame({'sample': 'oot', \n",
    "                            'actual': y_oot, \n",
    "                            'predicted' : pred_oot,\n",
    "                            'RT_CUSTOMER_ID': oot_keys[\"RT_CUSTOMER_ID\"], \n",
    "                             'APP_DATE': oot_keys[\"APP_DATE\"],\n",
    "                             'APP_ID': oot_keys[\"APP_ID\"]\n",
    "                              })\n",
    "    predictions = train_df.append([test_df, oot_df])\n",
    "    del train_df, test_df, oot_df, pred_train, pred_test, pred_oot\n",
    "    gc.collect()\n",
    "    perf_sum = predictions.groupby(\"sample\").agg(\"mean\").reset_index().drop(columns='RT_CUSTOMER_ID')\n",
    "    #perf_sum[['actual', 'predicted']] = perf_sum[['actual', 'predicted']].apply(lambda x: round(100*x, 2))\n",
    "    predictions.loc[:,'count'] = 1\n",
    "    \n",
    "    mae_train,mape_train = cal_mae_and_mape(predictions, sample='train', pred_name='predicted')\n",
    "    mae_test, mape_test = cal_mae_and_mape(predictions, sample='test', pred_name='predicted')\n",
    "    mae_oot, mape_oot = cal_mae_and_mape(predictions, sample='oot', pred_name='predicted')\n",
    "   \n",
    "    perf_sum['mae'] = 0\n",
    "    perf_sum.loc[perf_sum['sample'] == 'train', 'mae'] = mae_train\n",
    "    perf_sum.loc[perf_sum['sample'] == 'test', 'mae'] = mae_test\n",
    "    perf_sum.loc[perf_sum['sample'] == 'oot', 'mae'] = mae_oot\n",
    "    \n",
    "    perf_sum['mape'] = 0\n",
    "    perf_sum.loc[perf_sum['sample'] == 'train', 'mape'] = mape_train\n",
    "    perf_sum.loc[perf_sum['sample'] == 'test', 'mape'] = mape_test\n",
    "    perf_sum.loc[perf_sum['sample'] == 'oot', 'mape'] = mape_oot\n",
    "    \n",
    "  \n",
    "    save_params = params.copy()\n",
    "    save_params[\"num_boost_round\"] = num_boost_round\n",
    "    save_params[\"early_stopping_rounds\"] = early_stopping_rounds\n",
    "    save_params[\"verbose_eval\"] = verbose_eval\n",
    "    perf_sum[\"parameters\"] = str(save_params)\n",
    "    \n",
    "    ## feature importance \n",
    "    \n",
    "    # âweightâ: the number of times a feature is used to split the data across all trees.\n",
    "    # âgainâ: the average gain across all splits the feature is used in.\n",
    "    # âcoverâ: the average coverage across all splits the feature is used in.\n",
    "    # âtotal_gainâ: the total gain across all splits the feature is used in.\n",
    "    # âtotal_coverâ: the total coverage across all splits the feature is used in.\n",
    "    \n",
    "    importance_xgb = pd.DataFrame.from_dict(data=bst.get_score(importance_type='weight'), orient='index')\n",
    "    importance_xgb = importance_xgb.reset_index()\n",
    "    importance_xgb.columns = [\"features\",\"weight\"]\n",
    "    \n",
    "    for i in ['gain', 'cover', 'total_gain', 'total_cover']:\n",
    "        temp_imp = pd.DataFrame.from_dict(data=bst.get_score(importance_type=i), orient='index')\n",
    "        temp_imp.columns = [i]\n",
    "        importance_xgb = importance_xgb.merge(temp_imp, left_on=\"features\", right_index=True)\n",
    "        del temp_imp\n",
    "        gc.collect()\n",
    "        \n",
    "    importance_xgb[\"total_gain_score\"] =  importance_xgb[\"total_gain\"] / importance_xgb[\"total_gain\"].sum()\n",
    "    importance_xgb = importance_xgb.sort_values('total_gain_score', ascending=False)\n",
    "    del mape_train, mape_test, mape_oot, mae_train, mae_test, mae_oot, save_params\n",
    "    gc.collect()\n",
    "    return bst, predictions, perf_sum, importance_xgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##performance measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_measurement():\n",
    "    # performance measurement\n",
    "    train_sum_by_pred_score, train_sum_by_pred_row, fig_train_score, fig_train_row = create_performance_measurement_results(predictions[predictions['sample'] == 'train'], title=\"Train\")\n",
    "    test_sum_by_pred_score, test_sum_by_pred_row, fig_test_score, fig_test_row = create_performance_measurement_results(predictions[predictions['sample'] == 'test'], title=\"Test\")\n",
    "    oot_sum_by_pred_score, oot_sum_by_pred_row, fig_oot_score, fig_oot_row = create_performance_measurement_results(predictions[predictions['sample'] == 'oot'], title=\"Oot\")\n",
    "    return train_sum_by_pred_score, train_sum_by_pred_row, fig_train_score, fig_train_row, test_sum_by_pred_score, test_sum_by_pred_row, fig_test_score, fig_test_row, oot_sum_by_pred_score, oot_sum_by_pred_row, fig_oot_score, fig_oot_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "##performance for segments##\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mae_mape_for_segment(dfPredictions, segmentType, segmentTypeGroup, pred_name):\n",
    "  \n",
    "    try:\n",
    "        temp = dfPredictions.copy()\n",
    "        \n",
    "        if segmentType == \"all\":\n",
    "           mae_ = mean_absolute_error(temp['actual'], temp[pred_name])\n",
    "           mape_ = np.mean(np.abs((temp['actual']-temp[pred_name])/temp['actual']))\n",
    "        else:\n",
    "           mae_ = mean_absolute_error(temp.loc[temp[segmentType] == segmentTypeGroup]['actual'], temp.loc[temp[segmentType] == segmentTypeGroup][pred_name])\n",
    "           mape_ = np.mean(np.abs((temp.loc[temp[segmentType] == segmentTypeGroup]['actual']-temp.loc[temp[segmentType] == segmentTypeGroup][pred_name])/temp.loc[temp[segmentType] == segmentTypeGroup]['actual'])) \n",
    "        \n",
    "    except:    \n",
    "        print('Mae is not calculated for:' , segmentType, segmentTypeGroup)\n",
    "        mae_ = \"not calculated\"\n",
    "        mape_ = \"not calculated\"\n",
    "\n",
    "    del temp\n",
    "    gc.collect()\n",
    "    \n",
    "    return mae_,mape_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance_by_segment(df):\n",
    "    # performance measurement by different segmentation scenarios    \n",
    "    temp=df.copy()\n",
    "    #validation for PERIOD\n",
    "    temp['date'] = pd.to_datetime(temp['APP_DATE'])\n",
    "    temp['year'] = temp['date'].dt.year\n",
    "    temp['month'] = temp['date'].dt.month\n",
    "    temp['PERIOD'] = temp['year'].astype(str) + temp['month'].astype(str)\n",
    "    \n",
    "    temp=temp.drop(['date','year','month'],axis=1)\n",
    "    #validation for ACTUALINCOMEBUCKET\n",
    "    divide_by_score=np.arange(0, 100001, 1000)\n",
    "    temp['PREDINCOMEBUCKET'] = pd.cut(temp['predicted'], divide_by_score).astype('category')\n",
    "   \n",
    "    temp['ACTINCOMEBUCKET'] = pd.cut(temp['actual'], divide_by_score).astype('category')\n",
    "\n",
    "    \n",
    "    segment_summary_all_sample = temp.groupby(\"count\")[\"actual\", \"predicted\", \"count\"].agg(\"sum\")\n",
    "    segment_summary_all_sample.insert(loc = 0, column = 'segmentType', value = \"all\")\n",
    "    segment_summary_all_sample.insert(loc = 0, column = 'segmentTypeGroup', value = \"all\")\n",
    "    \n",
    "    segment_summary_period = temp.groupby(\"PERIOD\")[\"actual\", \"predicted\", \"count\"].agg(\"sum\").reset_index() \n",
    "    segment_summary_period=segment_summary_period[segment_summary_period['count']!=0]\n",
    "    segment_summary_period.insert(loc = 0, column = 'segmentType', value = \"PERIOD\")\n",
    "    segment_summary_period.rename(columns={'PERIOD':'segmentTypeGroup'}, inplace = True) \n",
    "\n",
    "    segment_summary_income_bucket = temp.groupby(\"PREDINCOMEBUCKET\")[\"actual\", \"predicted\", \"count\"].agg(\"sum\").reset_index() \n",
    "    segment_summary_income_bucket=segment_summary_income_bucket[segment_summary_income_bucket['count']!=0]\n",
    "    segment_summary_income_bucket.insert(loc = 0, column = 'segmentType', value = \"PREDINCOMEBUCKET\")\n",
    "    segment_summary_income_bucket.rename(columns={'PREDINCOMEBUCKET':'segmentTypeGroup'}, inplace = True)\n",
    "\n",
    "    segment_summary_decincome_bucket = temp.groupby(\"ACTINCOMEBUCKET\")[\"actual\", \"predicted\", \"count\"].agg(\"sum\").reset_index() \n",
    "    segment_summary_decincome_bucket=segment_summary_decincome_bucket[segment_summary_decincome_bucket['count']!=0]\n",
    "    segment_summary_decincome_bucket.insert(loc = 0, column = 'segmentType', value = \"ACTINCOMEBUCKET\")\n",
    "    segment_summary_decincome_bucket.rename(columns={'ACTINCOMEBUCKET':'segmentTypeGroup'}, inplace = True)\n",
    "\n",
    "\n",
    "    segment_summary_all = segment_summary_all_sample.append([segment_summary_period, segment_summary_income_bucket, segment_summary_decincome_bucket])\n",
    "    del segment_summary_all_sample, segment_summary_period, segment_summary_income_bucket, segment_summary_decincome_bucket\n",
    "    \n",
    "    segment_summary_all[\"avg_pd\"] = segment_summary_all[\"predicted\"]/segment_summary_all[\"count\"]\n",
    "   \n",
    "    segment_summary_all[\"mae\"] = np.nan\n",
    "    segment_summary_all[\"mape\"] = np.nan\n",
    "\n",
    "    \n",
    "    for segmentType in pd.unique(segment_summary_all['segmentType']):\n",
    "        for segmentTypeGroup in pd.unique(segment_summary_all.loc[segment_summary_all['segmentType']== segmentType]['segmentTypeGroup']):\n",
    "            maeSegment,mapeSegment = calculate_mae_mape_for_segment(temp, segmentType, segmentTypeGroup, \"predicted\")\n",
    "            segment_summary_all.loc[(segment_summary_all['segmentType'] == segmentType) & (segment_summary_all['segmentTypeGroup'] == segmentTypeGroup), 'mae'] = maeSegment\n",
    "            segment_summary_all.loc[(segment_summary_all['segmentType'] == segmentType) & (segment_summary_all['segmentTypeGroup'] == segmentTypeGroup), 'mape'] = mapeSegment\n",
    "\n",
    "    return segment_summary_all      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_measurement_for_segment():\n",
    "    # performance measurement\n",
    "    segment_summary_all_train = evaluate_performance_by_segment(predictions[predictions['sample'] == 'train'])\n",
    "    segment_summary_all_test = evaluate_performance_by_segment(predictions[predictions['sample'] == 'test'])\n",
    "    segment_summary_all_oot = evaluate_performance_by_segment(predictions[predictions['sample'] == 'oot'])\n",
    "    segment_summary_all = evaluate_performance_by_segment(predictions)\n",
    "\n",
    "    return segment_summary_all_train, segment_summary_all_test,segment_summary_all_oot, segment_summary_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "### Save Results ###\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(path):\n",
    "    print(\"\\nSaving Results...\")\n",
    "    # create folder\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    # save grid search results\n",
    "    if grid_search_:\n",
    "        xgb_gs_train.to_excel(path+\"fullgrid.xlsx\" )\n",
    "    \n",
    "    # save predictions\n",
    "#    predictions_calb.to_csv(path+\"predictions_calb.csv\" )\n",
    "    \n",
    "    # save performance results\n",
    "    perf_sum.to_excel(path+\"performance_summary.xlsx\" )\n",
    "    \n",
    "    # save comparison plot - actual vs predicted\n",
    "    with matplotlib.backends.backend_pdf.PdfPages(path+'Performance_Details.pdf') as pdf:\n",
    "        for i in [fig_train_score, fig_train_row, fig_test_score, fig_test_row, fig_oot_score, fig_oot_row]:\n",
    "            pdf.savefig(i)\n",
    "        \n",
    "    # save importance features' information\n",
    "    importance_xgb.to_excel(path+\"importance_xgb.xlsx\")   \n",
    "    \n",
    "    \n",
    "    # save model performance summary data\n",
    "    perf_dict = {'train_score': train_sum_by_pred_score, 'train_count': train_sum_by_pred_row,\n",
    "                 'test_score': test_sum_by_pred_score, 'test_count': test_sum_by_pred_row,\n",
    "                 'oot_score': oot_sum_by_pred_score, 'oot_count': oot_sum_by_pred_row}\n",
    "    \n",
    "    with pd.ExcelWriter(path+'Performance_Details_data.xlsx') as writer:\n",
    "        for name_ in perf_dict:\n",
    "            perf_dict[name_].to_excel(writer, sheet_name=name_)\n",
    "    \n",
    "    del perf_dict\n",
    "    gc.collect()\n",
    "    \n",
    "    # save gini performance by various segment breakdown\n",
    "    #segment_summary_all.to_excel(path+\"segment_breakdown.xlsx\")\n",
    "    \n",
    "    # save model performance summary data\n",
    "    perf_dict = {'summary_all_train': segment_summary_all_train,\n",
    "                 'summary_all_test': segment_summary_all_test,\n",
    "                 'summary_all_oot': segment_summary_all_oot,\n",
    "                 'summary_all': segment_summary_all}\n",
    "    \n",
    "    with pd.ExcelWriter(path+'Performance_Details_for_segment_data.xlsx') as writer:\n",
    "        for name_ in perf_dict:\n",
    "            perf_dict[name_].to_excel(writer, sheet_name=name_)\n",
    "    \n",
    "    del perf_dict\n",
    "    gc.collect()  \n",
    "    \n",
    "    \n",
    "    # save xgb model object\n",
    "    pickle.dump(bst, open(path+\"model_xgb.pkl\", 'wb'))\n",
    "    # load the xgb model from disk\n",
    "    #loaded_model = pickle.load(open(path+filename, 'rb'))\n",
    "    \n",
    "    # save pmml object\n",
    "    #sklearn2pmml(pipeline, path + str(\"xgboost_model.pmml\"), with_repr=True)\n",
    "    \n",
    "    #save pmml predictions\n",
    "    #pred_all.to_excel(path + str('predictions_with_pmml.xlsx'))\n",
    "    \n",
    "    # save pmml object\n",
    "    #sklearn2pmml(pipeline_ren, path + str(\"xgboost_model_renamed.pmml\"), with_repr=True)\n",
    "    \n",
    "    #save pmml predictions\n",
    "    #pred_all_ren.to_excel(path + str('predictions_with_pmml_renamed.xlsx'))\n",
    "    \n",
    "    # save character encoding matrix\n",
    "    #encoding_matrix.to_excel(path+\"encoding_matrix.xlsx\")\n",
    "    #encoding_matrix.to_pickle(path+\"encoding_matrix.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_preprocess(df, max_threshold):\n",
    "    '''\n",
    "    execute all functions defined for preprocessing\n",
    "    '''\n",
    "    na_report = create_na_report(df)\n",
    "    num_cols, char_cols = create_dtype_report(df)\n",
    "    new_df = eliminate_missing(df, na_report, max_threshold)\n",
    "    new_df = eliminate_single_unique(new_df)\n",
    "    #enc_df = create_encoding_matrix(new_df)\n",
    "    #new_df = encode_from_matrix(new_df, enc_df)\n",
    "    \n",
    "    #save enc_df for later use in prediction code\n",
    "    gc.collect()\n",
    "    print(\"\\nPreprocess is done...\")\n",
    "    return new_df#, enc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_by_index_pmml(df, key_var, train_index, test_index, oot_index):\n",
    "    # first get TARGET arrays\n",
    "    y_train, y_test, y_oot = df['TARGET'].iloc[train_index], df['TARGET'].iloc[test_index], df['TARGET'].iloc[oot_index]\n",
    "    \n",
    "    # get key values apart including TARGET\n",
    "    cols_ = df.columns[df.columns.isin(list(key_var))] #including TARGET\n",
    "    df_key_var = df[cols_]  #save key values\n",
    "    df_n = df.drop(cols_, axis=1)\n",
    "    \n",
    "    # set dataframes\n",
    "    X_train, X_test, X_oot = df_n.iloc[train_index], df_n.iloc[test_index], df_n.iloc[oot_index]\n",
    "    train_keys, test_keys, oot_keys = df_key_var.iloc[train_index], df_key_var.iloc[test_index], df_key_var.iloc[oot_index]\n",
    "\n",
    "    del df_n\n",
    "    gc.collect()\n",
    "    return X_train, X_test, X_oot, y_train, y_test, y_oot, train_keys, test_keys, oot_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset has 1076695 entries and 286 features\n",
      "0 columns eliminated due to missing values\n",
      "0 columns eliminated due to single unique values, namely: []\n",
      "\n",
      "Preprocess is done...\n",
      "\n",
      "Shape of dataframes; train: (787347,), test: (196837,), oot: (92511,)\n",
      "\n",
      "Percentage of dataframes; train: 73.13%, test: 18.28%, oot: 8.59%\n",
      "\n",
      "----final model----\n",
      "\n",
      "Shape of dataframes; train: (787347,), test: (196837,), oot: (92511,)\n",
      "\n",
      "Percentage of dataframes; train: 73.13%, test: 18.28%, oot: 8.59%\n",
      "\n",
      "\n",
      "[0]\ttrain-mae:4902.32715\teval-mae:4897.58838\n",
      "[10]\ttrain-mae:4434.26318\teval-mae:4430.21826\n",
      "[20]\ttrain-mae:4010.94409\teval-mae:4007.53980\n",
      "[30]\ttrain-mae:3628.07349\teval-mae:3625.26245\n",
      "[40]\ttrain-mae:3281.87988\teval-mae:3279.70703\n",
      "[50]\ttrain-mae:2969.28320\teval-mae:2967.65015\n",
      "[60]\ttrain-mae:2687.90601\teval-mae:2686.77466\n",
      "[70]\ttrain-mae:2435.71729\teval-mae:2435.10718\n",
      "[80]\ttrain-mae:2211.12817\teval-mae:2211.11133\n",
      "[90]\ttrain-mae:2013.11438\teval-mae:2014.03967\n",
      "[100]\ttrain-mae:1841.18347\teval-mae:1843.44287\n",
      "[110]\ttrain-mae:1694.81201\teval-mae:1698.72961\n",
      "[120]\ttrain-mae:1572.85767\teval-mae:1578.71411\n",
      "[130]\ttrain-mae:1473.39771\teval-mae:1481.25854\n",
      "[140]\ttrain-mae:1393.46094\teval-mae:1403.50317\n",
      "[150]\ttrain-mae:1330.03809\teval-mae:1342.48438\n",
      "[160]\ttrain-mae:1280.68738\teval-mae:1295.42273\n",
      "[170]\ttrain-mae:1242.66797\teval-mae:1259.58923\n",
      "[180]\ttrain-mae:1213.71777\teval-mae:1232.53687\n",
      "[190]\ttrain-mae:1192.04810\teval-mae:1212.52429\n",
      "[200]\ttrain-mae:1176.23389\teval-mae:1198.26306\n",
      "[210]\ttrain-mae:1165.30713\teval-mae:1188.56458\n",
      "[220]\ttrain-mae:1157.75513\teval-mae:1182.13452\n",
      "[230]\ttrain-mae:1153.17419\teval-mae:1178.53748\n",
      "[240]\ttrain-mae:1150.66052\teval-mae:1176.86462\n",
      "[250]\ttrain-mae:1149.75037\teval-mae:1176.57007\n",
      "[260]\ttrain-mae:1149.68420\teval-mae:1177.20984\n",
      "[267]\ttrain-mae:1150.25232\teval-mae:1178.17993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sgunduz.experian\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:101: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sample          mae\n",
      "0    oot  1218.747111\n",
      "1   test  1176.537479\n",
      "2  train  1149.856293\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"main parameters should be set before each run\"\"\"\n",
    "\n",
    "    grid_search_= False\n",
    "    save_results_= True\n",
    "    random_search = False\n",
    "    \n",
    "    \n",
    "    segment = 'kkbli_yeni' #kkbsiz,kkbli_yeni,kkbli_mevcut_sm, kkbli_mevcut_ou, kkbli_mevcut_emk,kkbli_mevcut_ku\n",
    "    \n",
    "\n",
    "    # key variables\n",
    "    key_var = [\"RT_CUSTOMER_ID\", \"APP_DATE\", \"APP_ID\", \"TARGET\"] # for management of data issues\n",
    "    key_vars = [\"RT_CUSTOMER_ID\", \"APP_DATE\",\"APP_ID\"] # for preparing data.table() for model estimation\n",
    "    \n",
    "    # define maximum acceptable percentage of missing information\n",
    "    max_threshold = 1\n",
    "    \n",
    "    # splitting percentage of development data into train nand test\n",
    "    splitting_perc = 0.2\n",
    "   \n",
    "    min_date = '2020-08-01' #oot date\n",
    "\n",
    "    # specify seed for random selection - to keep track of the chosen seed, for results' reproduction\n",
    "    seed = 1234\n",
    "    \n",
    "    ## diff_threshold for grid search\n",
    "    diff_threshold = 1000\n",
    "\n",
    "\n",
    "    trial = 'final'\n",
    "    t_string = str(trial)\n",
    "    today = date.today()\n",
    "    path = 'D:/gtp-files/Final/FAZ1_Modeller/{}-{}-{}/'\n",
    "    path = path.format(segment, t_string, today)\n",
    "    \n",
    "        ##datayi okutma##\n",
    "    directory = Path(\"D:/gtp-files/Final/\")\n",
    "    \n",
    "    data_directory = directory / \"Data_Files\"\n",
    "    #data okuma:\n",
    "    data=pd.read_csv(r'D:\\gtp-files\\Final\\3.Hedef DeÄiÅken Belirleme\\FAZ1\\KKBLI_YENI_v1\\KKBli_Yeni_target_final_old_sl.csv')\n",
    "\n",
    "    \n",
    "    df= data.copy()\n",
    "            \n",
    "    \n",
    "    df=df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "    ###############\n",
    "    ###Modelling###\n",
    "    ###############\n",
    "    \n",
    "    \n",
    "    #code execution:\n",
    "    df = execute_preprocess(df, max_threshold)\n",
    "    df = df.reset_index(drop = True)\n",
    "    train_index, test_index, oot_index=set_split_index(df, splitting_perc, seed, min_date)\n",
    "  \n",
    "    if grid_search_:\n",
    "        grid_params = {\n",
    "        # Parameters that we are going to tune.\n",
    "        'eta' : [0.01,0.05],  #0.01,0.05, #0.1\n",
    "        'max_depth': [9,12,15], #np.arange(3, 8, 2).tolist(), #3,5  #6\n",
    "        'min_child_weight': [#max(round(train_index.shape[0]*0.001),10), #retired iÃ§in hide\n",
    "                             #max(round(train_index.shape[0]*0.006),20),\n",
    "                             #round(train_index.shape[0]*0.008),\n",
    "                             #round(train_index.shape[0]*0.01),\n",
    "                             #round(train_index.shape[0]*0.02),\n",
    "                             #min(round(train_index.shape[0]*0.03),500),  #retired iÃ§in eklendi\n",
    "                             #min(round(train_index.shape[0]*0.05),750)  #retired iÃ§in eklenedi,self employed iÃ§in hide\n",
    "                             250,500,750],\n",
    "        'subsample': [1],\n",
    "        'colsample_bytree': [1],\n",
    "        'gamma' : [0,40,80], #40,60,80,100\n",
    "        'reg_alpha' : [0.9,0.5,0.1], #0.05,0.1\n",
    "        # Other parameters  \n",
    "        'objective': ['reg:squarederror'],\n",
    "        #eval_metric deÄiÅtirilecek:\n",
    "        'eval_metric' : ['mae'], #mae #mse # Use mean abs error rather than rmse (lower impact of outliers)\n",
    "        'booster' : ['gbtree'] #dart \n",
    "        }\n",
    "        xgb_gs_train, best_gs_iter, params = execute_grid_search(df, key_var, grid_params, splitting_perc, min_date, seed, random_search, diff_threshold, 432)    \n",
    "    else:\n",
    "        params = set_params(seed)\n",
    " \n",
    "    bst, predictions, perf_sum, importance_xgb = execute_final_model(df, key_var, params, splitting_perc, seed, num_boost_round=500, early_stopping_rounds=20, verbose_eval=10)\n",
    "    train_sum_by_pred_score, train_sum_by_pred_row, fig_train_score, fig_train_row, test_sum_by_pred_score, test_sum_by_pred_row, fig_test_score, fig_test_row, oot_sum_by_pred_score, oot_sum_by_pred_row, fig_oot_score, fig_oot_row = performance_measurement()    \n",
    "    #segment_summary_all = evaluate_performance_by_segment()    \n",
    "    segment_summary_all_train, segment_summary_all_test,segment_summary_all_oot, segment_summary_all = performance_measurement_for_segment()\n",
    "    \n",
    "    print(perf_sum[[\"sample\",\"mae\"]])\n",
    "    if save_results_:\n",
    "        save_results(path)\n",
    "    print('Done with model_building.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#powercurve iÃ§in:\n",
    "#pmml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_oot, y_train, y_test, y_oot, train_keys, test_keys, oot_keys = split_df_by_index_pmml(df, key_var, train_index, test_index, oot_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = X_train.copy()\n",
    "df_y = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = XGBRegressor(n_estimators = (bst.best_iteration +1),\n",
    "                              #early_stopping_rounds=early_stopping_rounds,\n",
    "                              learning_rate = params['eta'],\n",
    "                              max_depth = params['max_depth'],\n",
    "                              min_child_weight = params['min_child_weight'],\n",
    "                              subsample = params['subsample'],\n",
    "                              colsample_bytree = params['colsample_bytree'],\n",
    "                              gamma = params['gamma'],\n",
    "                              reg_alpha = params['reg_alpha'],\n",
    "                              objective = params['objective'],\n",
    "                              booster = params['booster'],\n",
    "                              eval_metric = params['eval_metric'],\n",
    "                              seed = params['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = PMMLPipeline([\n",
    "      (\"regressor\", regressor)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sgunduz.experian\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(df_X, df_y.ravel())\n",
    "pipeline.verify(df_X,zeroThreshold = 1e-6, precision = 1e-6)\n",
    "pipeline = make_pmml_pipeline(pipeline, active_fields = df_X.columns.values, target_fields = df_y.name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_pmml_train = pipeline.predict(X_train)\n",
    "predict_pmml_test = pipeline.predict(X_test)\n",
    "predict_pmml_oot = pipeline.predict(X_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_pmml_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions[predictions['sample']=='train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmml_train_df = pd.DataFrame({'sample': 'train', \n",
    "                              'actual': y_train, \n",
    "                              'predicted_pmml' : predict_pmml_train,\n",
    "                              'RT_CUSTOMER_ID': train_keys[\"RT_CUSTOMER_ID\"], \n",
    "                              #'REPORT_DATE': train_keys[\"REPORT_DATE\"],\n",
    "                              'APP_ID': train_keys[\"APP_ID\"]\n",
    "                              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmml_test_df = pd.DataFrame({'sample': 'test', \n",
    "                             'actual': y_test, \n",
    "                             'predicted_pmml' : predict_pmml_test,\n",
    "                             'RT_CUSTOMER_ID': test_keys[\"RT_CUSTOMER_ID\"], \n",
    "                             #'REPORT_DATE': test_keys[\"REPORT_DATE\"],\n",
    "                             'APP_ID': test_keys[\"APP_ID\"]\n",
    "                              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmml_oot_df = pd.DataFrame({'sample': 'oot', \n",
    "                            'actual': y_oot, \n",
    "                            'predicted_pmml' : predict_pmml_oot,\n",
    "                            'RT_CUSTOMER_ID': oot_keys[\"RT_CUSTOMER_ID\"], \n",
    "                             #'REPORT_DATE': oot_keys[\"REPORT_DATE\"],\n",
    "                             'APP_ID': oot_keys[\"APP_ID\"]\n",
    "                              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pmml = pmml_train_df.append([pmml_test_df, pmml_oot_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all =pd.merge(predictions , predictions_pmml, left_on=['APP_ID'], right_on=['APP_ID'], how='left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_x</th>\n",
       "      <th>actual_x</th>\n",
       "      <th>predicted</th>\n",
       "      <th>RT_CUSTOMER_ID_x</th>\n",
       "      <th>APP_DATE</th>\n",
       "      <th>APP_ID</th>\n",
       "      <th>count</th>\n",
       "      <th>sample_y</th>\n",
       "      <th>actual_y</th>\n",
       "      <th>predicted_pmml</th>\n",
       "      <th>RT_CUSTOMER_ID_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>3185.890376</td>\n",
       "      <td>4121.837891</td>\n",
       "      <td>21105622.0</td>\n",
       "      <td>2018-07-27 22:18:40</td>\n",
       "      <td>TIK73548321</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>3185.890376</td>\n",
       "      <td>4121.837891</td>\n",
       "      <td>21105622.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>2670.048466</td>\n",
       "      <td>2935.000488</td>\n",
       "      <td>19853081.0</td>\n",
       "      <td>2017-11-14 08:58:59</td>\n",
       "      <td>KMH31023133</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2670.048466</td>\n",
       "      <td>2935.000488</td>\n",
       "      <td>19853081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>2960.895900</td>\n",
       "      <td>3107.343994</td>\n",
       "      <td>22404143.0</td>\n",
       "      <td>2019-03-15 09:35:58</td>\n",
       "      <td>TIK113681703</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2960.895900</td>\n",
       "      <td>3107.343994</td>\n",
       "      <td>22404143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>3072.870132</td>\n",
       "      <td>4454.599609</td>\n",
       "      <td>23654657.0</td>\n",
       "      <td>2020-06-15 00:00:00</td>\n",
       "      <td>LMT29095272</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>3072.870132</td>\n",
       "      <td>4454.599609</td>\n",
       "      <td>23654657.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>4595.327632</td>\n",
       "      <td>4357.610840</td>\n",
       "      <td>23206648.0</td>\n",
       "      <td>2019-11-11 11:16:57</td>\n",
       "      <td>TIK150271792</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>4595.327632</td>\n",
       "      <td>4357.610840</td>\n",
       "      <td>23206648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076690</th>\n",
       "      <td>oot</td>\n",
       "      <td>2912.984500</td>\n",
       "      <td>3530.733154</td>\n",
       "      <td>25004215.0</td>\n",
       "      <td>2020-08-28 16:05:57</td>\n",
       "      <td>TIK204334886</td>\n",
       "      <td>1</td>\n",
       "      <td>oot</td>\n",
       "      <td>2912.984500</td>\n",
       "      <td>3530.733154</td>\n",
       "      <td>25004215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076691</th>\n",
       "      <td>oot</td>\n",
       "      <td>5048.000000</td>\n",
       "      <td>3319.709229</td>\n",
       "      <td>25080201.0</td>\n",
       "      <td>2020-09-29 10:48:42</td>\n",
       "      <td>TIK207215078</td>\n",
       "      <td>1</td>\n",
       "      <td>oot</td>\n",
       "      <td>5048.000000</td>\n",
       "      <td>3319.709229</td>\n",
       "      <td>25080201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076692</th>\n",
       "      <td>oot</td>\n",
       "      <td>6524.681400</td>\n",
       "      <td>8997.050781</td>\n",
       "      <td>24983728.0</td>\n",
       "      <td>2020-08-21 13:52:07</td>\n",
       "      <td>TIK203744152</td>\n",
       "      <td>1</td>\n",
       "      <td>oot</td>\n",
       "      <td>6524.681400</td>\n",
       "      <td>8997.050781</td>\n",
       "      <td>24983728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076693</th>\n",
       "      <td>oot</td>\n",
       "      <td>5048.500000</td>\n",
       "      <td>3224.490967</td>\n",
       "      <td>24917050.0</td>\n",
       "      <td>2020-08-19 15:10:04</td>\n",
       "      <td>TIK203544191</td>\n",
       "      <td>1</td>\n",
       "      <td>oot</td>\n",
       "      <td>5048.500000</td>\n",
       "      <td>3224.490967</td>\n",
       "      <td>24917050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076694</th>\n",
       "      <td>oot</td>\n",
       "      <td>4972.772500</td>\n",
       "      <td>5065.347656</td>\n",
       "      <td>24991770.0</td>\n",
       "      <td>2020-08-25 00:00:00</td>\n",
       "      <td>KK32400481</td>\n",
       "      <td>1</td>\n",
       "      <td>oot</td>\n",
       "      <td>4972.772500</td>\n",
       "      <td>5065.347656</td>\n",
       "      <td>24991770.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1076695 rows Ã 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sample_x     actual_x    predicted  RT_CUSTOMER_ID_x  \\\n",
       "0          train  3185.890376  4121.837891        21105622.0   \n",
       "1          train  2670.048466  2935.000488        19853081.0   \n",
       "2          train  2960.895900  3107.343994        22404143.0   \n",
       "3          train  3072.870132  4454.599609        23654657.0   \n",
       "4          train  4595.327632  4357.610840        23206648.0   \n",
       "...          ...          ...          ...               ...   \n",
       "1076690      oot  2912.984500  3530.733154        25004215.0   \n",
       "1076691      oot  5048.000000  3319.709229        25080201.0   \n",
       "1076692      oot  6524.681400  8997.050781        24983728.0   \n",
       "1076693      oot  5048.500000  3224.490967        24917050.0   \n",
       "1076694      oot  4972.772500  5065.347656        24991770.0   \n",
       "\n",
       "                    APP_DATE        APP_ID  count sample_y     actual_y  \\\n",
       "0        2018-07-27 22:18:40   TIK73548321      1    train  3185.890376   \n",
       "1        2017-11-14 08:58:59   KMH31023133      1    train  2670.048466   \n",
       "2        2019-03-15 09:35:58  TIK113681703      1    train  2960.895900   \n",
       "3        2020-06-15 00:00:00   LMT29095272      1    train  3072.870132   \n",
       "4        2019-11-11 11:16:57  TIK150271792      1    train  4595.327632   \n",
       "...                      ...           ...    ...      ...          ...   \n",
       "1076690  2020-08-28 16:05:57  TIK204334886      1      oot  2912.984500   \n",
       "1076691  2020-09-29 10:48:42  TIK207215078      1      oot  5048.000000   \n",
       "1076692  2020-08-21 13:52:07  TIK203744152      1      oot  6524.681400   \n",
       "1076693  2020-08-19 15:10:04  TIK203544191      1      oot  5048.500000   \n",
       "1076694  2020-08-25 00:00:00    KK32400481      1      oot  4972.772500   \n",
       "\n",
       "         predicted_pmml  RT_CUSTOMER_ID_y  \n",
       "0           4121.837891        21105622.0  \n",
       "1           2935.000488        19853081.0  \n",
       "2           3107.343994        22404143.0  \n",
       "3           4454.599609        23654657.0  \n",
       "4           4357.610840        23206648.0  \n",
       "...                 ...               ...  \n",
       "1076690     3530.733154        25004215.0  \n",
       "1076691     3319.709229        25080201.0  \n",
       "1076692     8997.050781        24983728.0  \n",
       "1076693     3224.490967        24917050.0  \n",
       "1076694     5065.347656        24991770.0  \n",
       "\n",
       "[1076695 rows x 11 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving Results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sgunduz.experian\\Anaconda3\\lib\\subprocess.py:844: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "C:\\Users\\sgunduz.experian\\Anaconda3\\lib\\subprocess.py:849: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stderr = io.open(errread, 'rb', bufsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with model_building.py\n"
     ]
    }
   ],
   "source": [
    "if save_results_:\n",
    "    save_results(path)\n",
    "    print('Done with model_building.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "###Analizler Ãzet###\n",
    "####################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sgunduz.experian\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3418: DtypeWarning: Columns (20,55,90,198,234,255,308,309,310,311,323,324) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "data_all = pd.read_csv(r'D:\\gtp-files\\Final\\3.Hedef DeÄiÅken Belirleme\\FAZ1\\KKBLI_YENI_v1\\KKBli_Yeni_target_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v1=pd.merge(df,data_all[['APP_ID','KKB_FLAG','ANA_GRUP_FLAG','APP_SH_DOC_INCOME','RT_MODEL_EST_INCOME',\n",
    "                                 'APP_SH_DECL_INCOME','APP_SALARY_AMT_LM','SKY_FLAG_URUN',\n",
    "                                 'AGE_GRUP','YENISALARYCUSTFLAG','income_seg','APP_FINAL_DECISION',\n",
    "                                 'RT_WORKING_TYPE_DESC', 'RT_SECTOR_TYPE_DESC', 'RT_OCCUPATION', \n",
    "                                 'DOC_INCOME_FINAL','target_w_inf','inflation']],\n",
    "               on=['APP_ID'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v1['DOC_INCOME_FLAG'] = np.where(df_v1['APP_SH_DOC_INCOME'] > 0, 1,0)\n",
    "df_v1['DECL_INCOME_FLAG'] = np.where(df_v1['APP_SH_DECL_INCOME'] > 0, 1,0)\n",
    "df_v1['APP_SALARY_AMT_LM_FLAG'] = np.where(df_v1['APP_SALARY_AMT_LM'] > 0, 1,0)\n",
    "df_v1['RT_KKB_CC_O_TOT_LIM_FLAG'] = np.where(df_v1['RT_KKB_CC_O_TOT_LIM'] > 0, 1,0)\n",
    "df_v1['RT_KKB_CC_MAX_O_C_LIM_L1Y_FLAG'] = np.where(df_v1['RT_KKB_CC_MAX_O_C_LIM_L1Y'] > 0, 1,0)\n",
    "df_v1['RT_KKB_INST_O_TOT_INST_AMT_FLAG'] = np.where(df_v1['RT_KKB_INST_O_TOT_INST_AMT'] > 0, 1,0)\n",
    "df_v1['RT_MODEL_EST_INCOME_FLAG']=np.where(df_v1['RT_MODEL_EST_INCOME']>0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle as cxo \n",
    "import sqlalchemy\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v=pd.merge(predictions,df_v1,on=['APP_ID','APP_DATE','RT_CUSTOMER_ID'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sgunduz.experian\\Anaconda3\\lib\\site-packages\\sqlalchemy\\dialects\\oracle\\base.py:1368: SAWarning: Oracle version (19, 7, 0, 0, 0) is known to have a maximum identifier length of 128, rather than the historical default of 30. SQLAlchemy 1.4 will use 128 for this database; please set max_identifier_length=128 in create_engine() in order to test the application with this new length, or set to 30 in order to assure that 30 continues to be used.  In particular, pay close attention to the behavior of database migrations as dynamically generated names may change. See the section 'Max Identifier Lengths' in the SQLAlchemy Oracle dialect documentation for background.\n",
      "  util.warn(\n"
     ]
    }
   ],
   "source": [
    "oracle_db=sqlalchemy.create_engine(\"oracle+cx_oracle://SASGELIRTAHMIN:DDzVB4597_PHZK239+@dbtexa.vakifbank.intra:1854/?service_name=DWHTEST\")\n",
    "connection=oracle_db.connect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|âââââ                                      | 2/20 [00:41<06:17, 20.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03822549800042907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql=\"SELECT APP_ID,S314 FROM SPSSDM.DM_BRY_SEGMENT_KKBLI_YENI_S314\" \n",
    "df_chunk=pd.read_sql(sql,connection,chunksize=1000000) \n",
    "chunklist= [] \n",
    "for chunk in tqdm(df_chunk,total=20):\n",
    "    chunklist.append(chunk) \n",
    "gc.collect()\n",
    "\n",
    "start_time=timeit.default_timer() \n",
    "df_sm=pd.concat(chunklist,ignore_index=True)\n",
    "print(timeit.default_timer()-start_time) \n",
    "\n",
    "del chunklist, df_chunk, chunk \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sm.columns = map(str.upper,df_sm.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sm['S314_flag']=np.where(df_sm['S314']>0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1=pd.merge(predictions_v,df_sm[['APP_ID','S314','S314_flag']],on=['APP_ID'],how='left') #,'APP_DATE','RT_CUSTOMER_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1['S314'] = predictions_v1['S314']*predictions_v1['inflation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1['actual_grp'] = np.where(predictions_v1['actual'] ==0, '0',\n",
    "                                     np.where(predictions_v1['actual'] < 2000, '<2000',\n",
    "                                              np.where(predictions_v1['actual'] < 3000, '<3000',\n",
    "                                                       np.where(predictions_v1['actual'] < 5000, '<5000',\n",
    "                                                                np.where(predictions_v1['actual'] < 7000, '<7000',\n",
    "                                                                         np.where(predictions_v1['actual'] < 10000, '<10000',\n",
    "                                                                                  np.where(predictions_v1['actual'] < 15000, '<15000',\n",
    "                                                                                           np.where(predictions_v1['actual'] < 20000, '<20000',\n",
    "                                                                                                    np.where(predictions_v1['actual'] < 50000, '<50000',\n",
    "                                                                                                             np.where(predictions_v1['actual'] >= 50000, '>=50000','Unknown'))))))))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1['pred_grp'] = np.where(predictions_v1['predicted'] ==0, '0',\n",
    "                                     np.where(predictions_v1['predicted'] < 2000, '<2000',\n",
    "                                              np.where(predictions_v1['predicted'] < 3000, '<3000',\n",
    "                                                       np.where(predictions_v1['predicted'] < 5000, '<5000',\n",
    "                                                                np.where(predictions_v1['predicted'] < 7000, '<7000',\n",
    "                                                                         np.where(predictions_v1['predicted'] < 10000, '<10000',\n",
    "                                                                                  np.where(predictions_v1['predicted'] < 15000, '<15000',\n",
    "                                                                                           np.where(predictions_v1['predicted'] < 20000, '<20000',\n",
    "                                                                                                    np.where(predictions_v1['predicted'] < 50000, '<50000',\n",
    "                                                                                                             np.where(predictions_v1['predicted'] >= 50000, '>=50000','Unknown'))))))))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1['model_grp'] = np.where(predictions_v1['RT_MODEL_EST_INCOME'] ==0, '0',\n",
    "                                     np.where(predictions_v1['RT_MODEL_EST_INCOME'] < 2000, '<2000',\n",
    "                                              np.where(predictions_v1['RT_MODEL_EST_INCOME'] < 3000, '<3000',\n",
    "                                                       np.where(predictions_v1['RT_MODEL_EST_INCOME'] < 5000, '<5000',\n",
    "                                                                np.where(predictions_v1['RT_MODEL_EST_INCOME'] < 7000, '<7000',\n",
    "                                                                         np.where(predictions_v1['RT_MODEL_EST_INCOME'] < 10000, '<10000',\n",
    "                                                                                  np.where(predictions_v1['RT_MODEL_EST_INCOME'] < 15000, '<15000',\n",
    "                                                                                           np.where(predictions_v1['RT_MODEL_EST_INCOME'] < 20000, '<20000',\n",
    "                                                                                                    np.where(predictions_v1['RT_MODEL_EST_INCOME'] < 50000, '<50000',\n",
    "                                                                                                             np.where(predictions_v1['RT_MODEL_EST_INCOME'] >= 50000, '>=50000','Unknown'))))))))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1['S314_grp'] = np.where(predictions_v1['S314'] ==0, '0',\n",
    "                                     np.where(predictions_v1['S314'] < 2000, '<2000',\n",
    "                                              np.where(predictions_v1['S314'] < 3000, '<3000',\n",
    "                                                       np.where(predictions_v1['S314'] < 5000, '<5000',\n",
    "                                                                np.where(predictions_v1['S314'] < 7000, '<7000',\n",
    "                                                                         np.where(predictions_v1['S314'] < 10000, '<10000',\n",
    "                                                                                  np.where(predictions_v1['S314'] < 15000, '<15000',\n",
    "                                                                                           np.where(predictions_v1['S314'] < 20000, '<20000',\n",
    "                                                                                                    np.where(predictions_v1['S314'] < 50000, '<50000',\n",
    "                                                                                                             np.where(predictions_v1['S314'] >= 50000, '>=50000','Unknown'))))))))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1['act_pred']=predictions_v1['actual']-predictions_v1['predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1['act_pred_grp'] = np.where(predictions_v1['act_pred'] <= -20000, '<=-20000',\n",
    "                             np.where(predictions_v1['act_pred'] < -15000, '<-15000',\n",
    "                             np.where(predictions_v1['act_pred'] < -10000, '<-10000',\n",
    "                             np.where(predictions_v1['act_pred'] < -7000, '<-7000',\n",
    "                             np.where(predictions_v1['act_pred'] < -5000, '<-5000',\n",
    "                             np.where(predictions_v1['act_pred'] < -3000, '<-3000',\n",
    "                             np.where(predictions_v1['act_pred'] < -2000, '<-2000',\n",
    "                             np.where(predictions_v1['act_pred'] < -1000, '<-1000',\n",
    "                             np.where(predictions_v1['act_pred'] < -500, '<-500',\n",
    "                             np.where(predictions_v1['act_pred'] < 0, '<0',\n",
    "                             np.where(predictions_v1['act_pred'] ==0, '0',\n",
    "                             np.where(predictions_v1['act_pred'] < 500, '<500', \n",
    "                             np.where(predictions_v1['act_pred'] < 1000, '<1000',         \n",
    "                             np.where(predictions_v1['act_pred'] < 2000, '<2000',\n",
    "                             np.where(predictions_v1['act_pred'] < 3000, '<3000',\n",
    "                             np.where(predictions_v1['act_pred'] < 5000, '<5000',\n",
    "                             np.where(predictions_v1['act_pred'] < 7000, '<7000',\n",
    "                             np.where(predictions_v1['act_pred'] < 10000, '<10000',\n",
    "                             np.where(predictions_v1['act_pred'] < 15000, '<15000',\n",
    "                             np.where(predictions_v1['act_pred'] < 20000, '<20000',\n",
    "                             np.where(predictions_v1['act_pred'] >= 20000, '>=20000',\n",
    "                                      'Unknown')))))))))))))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1['model_pred']=predictions_v1['RT_MODEL_EST_INCOME']-predictions_v1['predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1['model_pred_grp'] = np.where(predictions_v1['model_pred'] <= -20000, '<=-20000',\n",
    "                             np.where(predictions_v1['model_pred'] < -15000, '<-15000',\n",
    "                             np.where(predictions_v1['model_pred'] < -10000, '<-10000',\n",
    "                             np.where(predictions_v1['model_pred'] < -7000, '<-7000',\n",
    "                             np.where(predictions_v1['model_pred'] < -5000, '<-5000',\n",
    "                             np.where(predictions_v1['model_pred'] < -3000, '<-3000',\n",
    "                             np.where(predictions_v1['model_pred'] < -2000, '<-2000',\n",
    "                             np.where(predictions_v1['model_pred'] < -1000, '<-1000',\n",
    "                             np.where(predictions_v1['model_pred'] < -500, '<-500',\n",
    "                             np.where(predictions_v1['model_pred'] < 0, '<0',\n",
    "                             np.where(predictions_v1['model_pred'] ==0, '0',\n",
    "                             np.where(predictions_v1['model_pred'] < 500, '<500', \n",
    "                             np.where(predictions_v1['model_pred'] < 1000, '<1000',         \n",
    "                             np.where(predictions_v1['model_pred'] < 2000, '<2000',\n",
    "                             np.where(predictions_v1['model_pred'] < 3000, '<3000',\n",
    "                             np.where(predictions_v1['model_pred'] < 5000, '<5000',\n",
    "                             np.where(predictions_v1['model_pred'] < 7000, '<7000',\n",
    "                             np.where(predictions_v1['model_pred'] < 10000, '<10000',\n",
    "                             np.where(predictions_v1['model_pred'] < 15000, '<15000',\n",
    "                             np.where(predictions_v1['model_pred'] < 20000, '<20000',\n",
    "                             np.where(predictions_v1['model_pred'] >= 20000, '>=20000',\n",
    "                                      'Unknown')))))))))))))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1['error'] = abs((predictions_v1['predicted'] - predictions_v1['actual'])/predictions_v1['actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1['error_grp'] = np.where(predictions_v1['error'] < 0.15, '0-15',\n",
    "                              np.where(predictions_v1['error'] < 0.30, '15-30',\n",
    "                              np.where(predictions_v1['error'] < 0.50, '30-50',\n",
    "                              np.where(predictions_v1['error'] < 0.75, '50-75',\n",
    "                              np.where(predictions_v1['error'] >= 0.75, '75+',\n",
    "                              'Unknown')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1['error_model'] = abs((predictions_v1['predicted'] - predictions_v1['RT_MODEL_EST_INCOME'])/predictions_v1['RT_MODEL_EST_INCOME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1['error_model_grp'] = np.where(predictions_v1['error_model'] < 0.15, '0-15',\n",
    "                              np.where(predictions_v1['error_model'] < 0.30, '15-30',\n",
    "                              np.where(predictions_v1['error_model'] < 0.50, '30-50',\n",
    "                              np.where(predictions_v1['error_model'] < 0.75, '50-75',\n",
    "                              np.where(predictions_v1['error_model'] >= 0.75, '75+',\n",
    "                              'Unknown')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1['count']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078646"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_v1['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1=predictions_v1.fillna(-9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deneme \n",
    "# tablo oluÅturma\n",
    "predictions_v2= pd.pivot_table(predictions_v1,index=['sample','actual_grp','pred_grp','model_grp','act_pred_grp','model_pred_grp',\n",
    "                                                     'error_grp','error_model_grp',\n",
    "                                                     'ANA_GRUP_FLAG', 'RT_WORKING_TYPE_DESC', \n",
    "                                                     'RT_SECTOR_TYPE_DESC', 'RT_OCCUPATION',  \n",
    "                       'MESLEK_SEGMENT', 'KKB_FLAG', 'S314_flag','S314_grp',\n",
    "                       'APP_SALARY_AMT_LM_FLAG', 'APP_SALARYCUST_FLAG','RT_MODEL_EST_INCOME_FLAG',\n",
    "                       'RT_KKB_CC_O_TOT_LIM_FLAG','RT_KKB_CC_MAX_O_C_LIM_L1Y_FLAG',\n",
    "                       'M144','DECL_INCOME_FLAG','RT_KKB_INST_O_TOT_INST_AMT_FLAG',\n",
    "                       'SKY_FLAG_URUN','AGE_GRUP','YENISALARYCUSTFLAG','income_seg','APP_FINAL_DECISION',\n",
    "                       'DOC_INCOME_FLAG'],\n",
    "                            aggfunc={'APP_SH_DECL_INCOME' : np.sum,\n",
    "                                     'APP_SH_DOC_INCOME' : np.sum, \n",
    "                                     'RT_MODEL_EST_INCOME' : np.sum,\n",
    "                                     'S314':np.sum,\n",
    "                                     'APP_SALARY_AMT_LM' :np.sum,\n",
    "                                     'DOC_INCOME_FINAL' :np.sum , 'target_w_inf' : np.sum,\n",
    "                                     'count' : np.sum, \n",
    "                                     'RT_KKB_CC_O_TOT_LIM' : np.sum, 'RT_KKB_CC_MAX_O_C_LIM_L1Y' : np.sum,\n",
    "                                     'RT_KKB_INST_O_TOT_INST_AMT': np.sum,\n",
    "                                     'actual':np.sum,\n",
    "                                     'predicted':np.sum\n",
    "                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v2.reset_index().to_excel(path + str(\"Analysis_perf.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_v1.to_csv(path + str(\"AllData_KKBli_Yeni.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##BURADAN SONRASI ÃALIÅTIRILMAYACAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_matrix['variable'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_enc = pd.merge(predictions_v1,data[['APP_ID','MESLEK_SEGMENT', 'RT_CUST_SEGMENT', 'APP_BANK_REGION_CODE',\n",
    "       'M144']],on='APP_ID',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_enc=predictions_enc.fillna('-9999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = ExcelWriter(path + str('Encoding_List.xlsx'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ('MESLEK_SEGMENT','RT_CUST_SEGMENT','APP_BANK_REGION_CODE','M144'):\n",
    "    predictions_enc[[str(i)+str('_x'),str(i)+str('_y'),'APP_ID']].groupby([str(i)+str('_x'),str(i)+str('_y')]).count().reset_index().to_excel(writer, sheet_name = str(i),index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
